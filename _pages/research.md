---
permalink: /research/
title: "Research Activities"
author_profile: true
classes: wide
---

## PhD (ongoing)<br/>Neuromorphic processing of vocal and neural data<br/>INSERM, Grenoble Institute des Neurosciences (Mar '21 - present)

This work is a part of the [**ANR**](https://anr.fr/en/){:target="_blank" rel="noopener"} [**Brain-Net**](https://sites.google.com/view/brainnet-project/accueil){:target="_blank" rel="noopener"} project in collaboration with academic and industrial partners. The goal of my thesis is to develop unsupervised Spiking Neural Networks (**SNNs**) to classify spectro-temporal data. 

<font size="4.5"><b>Conferences</b></font>

<span style="color:green">Neuroscience 2022</span> - San Diego, California, USA - November 2022\
Poster - Unsupervised classification of vocal and speech patterns with artificial Spiking Neural Networks

<span style="color:green">CORTICO Days 2022</span> - Autrans, France - March 2022\
Poster - Development of an unsupervised Spiking Neural Network for the classification of spectro-temporal patterns

<span style="color:green">Neuroscience 2021</span> - virtual - November 2021\
Poster - Development of an unsupervised Spiking Neural Network for vocal and speech patterns classification

<font size="4.5"><b>Scientific Training</b></font>

<span style="color:green">ISRC-CN3 Autumn School</span> - Derry, United Kingdom - October 2022\
Computational Neuroscience, Neurotechnology and Neuro-inspired AI Autumn School


<p align="center">
  <img src="https://saideepesh.github.io/images/1666916373934-E.jpg?raw=true">
</p>


<p align="center">
  <i>ISRC-CN3 2022 formal dinner - Derry, United Kingdom</i>
</p>

## Artificial Intelligence Research Internship<br/>Development of an unsupervised SNN for vocalization classification<br/>INSERM (May - Oct '20)

This work was a part of the [European Union Horizon 2020 Project](https://ec.europa.eu/programmes/horizon2020/en){:target="_blank" rel="noopener"}.

Developed an unsupervised Spiking Neural Network (**SNN**) with Spike-Timing-Dependent-Plasticity (**STDP**) for classification of vocalizations.

- Encoded raw analog audio into discrete spike trains with 'time-to-first-spike' encoding.
- Implemented a Low-Threshold-Spiking (LTS) Neuron model to mimic the activity of biological neurons by introducing a temporal dimension to the activation of neurons.
- Implemented the STDP learning rule to enhance learning by updating the synaptic weights of the network.


## Research Internship<br/>Analysis of minipig vocalization data<br/>INSERM (May - Oct '18)

Analyzed vocalization data and attempted to cluster them with Machine Learning algorithms like Principal Component Analysis (**PCA**) in order to facilitate mapping with cortical activity; critical for the development of a Brain-Computer Interface (BCI).

- Analyzed Minipig Vocalization Data (MVD) to facilitate mapping between MVD and cortical data.
- Studied spectrograms and labelled audio files of the vocalization data as grunts, squeals and screams using Spike2.
- Performed data cleaning and dimensionality reduction of the data through spectrogram analysis and noise removal.
- Coded functions to successfully implement clustering algorithms like PCA and t-SNE using MATLAB.
- **Techniques Used**: Spectrogram Analysis, Principal Component Analysis, t-SNE, Independent Component Analysis
